{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25dd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from Experiment import Experiment\n",
    "from AcquisitionFuncs import *\n",
    "from Regressors import GaussianProcessReg\n",
    "from Kernels import *\n",
    "from Algorithms import opt_routine, OptaxAcqAlgBuilder\n",
    "import optax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be used as a non-trivial prior later\n",
    "def quadratic(x, a=0.5, b=0, c=0):\n",
    "    return jnp.ravel(a * x ** 2 + b * x + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa4e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some labelled data\n",
    "num_points = 5\n",
    "X0 = jnp.asarray(list(np.linspace(0., 1., num=num_points))).reshape((num_points, 1))\n",
    "y0 = jnp.asarray([0., 0.0078125 , 0.25, 0.07031249, 0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015ba91",
   "metadata": {},
   "source": [
    "# Showing how the API works - initialising an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90709b6d",
   "metadata": {},
   "source": [
    "Miscellaneous examples demonstrating how the API works ---initialisation of an Experiment, fitting of a GP to data, automatic inference of kernel hyperparameters by MLE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8fc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. user doesn't even supply data, throws up error\n",
    "exp = Experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92efc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. no user input, default RBF kernel with parameters inferred by MLE\n",
    "exp = Experiment(X0, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. no user input, but mle flag turned off: default RBF kernel but parameters initialised as None\n",
    "exp = Experiment(X0, y0, mle=False)\n",
    "exp.model.fit(X0, y0)  # We can't actually fit because we haven't specified \n",
    "# the kernel hyper-parameters, so this just tells us so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4784f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. user input from outset: default RBF kernel, all parameters provided\n",
    "exp = Experiment(X0, y0, kernel_hyperparams={'sigma': 0.5, 'lengthscale': 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. user input from outset: periodic kernel, all parameters provided\n",
    "exp = Experiment(X0, y0, kernel_type='Periodic', \n",
    "                 kernel_hyperparams={'sigma': 0.5, 'lengthscale': 0.01, 'period': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3414bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. user input from outset: default RBF kernel, not all parameters provided (mle called)\n",
    "exp = Experiment(X0, y0, kernel_hyperparams={'sigma': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. user input from outset: specified kernel, non-default prior, not all parameters provided (mle called)\n",
    "exp = Experiment(X0, y0, kernel_type='Periodic', kernel_hyperparams={'sigma': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. same as above but with Matern kernel ---the order, considered to be discreet (n+1/2), cannot be optimised and is set\n",
    "# to 3/2 by default. --running but producing 'nan' for lengthscale\n",
    "exp = Experiment(X0, y0, kernel_type='Matern', kernel_hyperparams={'sigma': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. user input from outset: non-default prior mean, default prior, not all parameters provided (MLE called)\n",
    "exp = Experiment(X0, y0, kernel_hyperparams={'sigma': 0.5}, prior_mean=quadratic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. user resetting all hyper-parameters after an initial fitting with MLE\n",
    "exp = Experiment(X0, y0)\n",
    "exp.model.kernel.sigma = 0.25\n",
    "exp.model.kernel.lengthscale = 0.06\n",
    "exp.model.fit(X0, y0)  # need to re-fit the model, this is not automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ca391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. user resetting only some of the hyper-parameters\n",
    "exp = Experiment(X0, y0)\n",
    "exp.model.kernel.sigma = 0.3\n",
    "exp.model.kernel.lengthscale = None\n",
    "exp.maximum_likelihood_estimation()  # need to estimate remaining hyper-param, this is not automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85683db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. user initialising experiment but turning off initial MLE\n",
    "exp = Experiment(X0, y0, mle=False)\n",
    "exp.model.kernel.sigma = 0.3\n",
    "exp.model.kernel.lengthscale = None\n",
    "exp.maximum_likelihood_estimation()  # need to estimate remaining hyper-param, this is not automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. user resetting prior mean function\n",
    "exp = Experiment(X0, y0, kernel_type='Periodic', kernel_hyperparams={'sigma': 0.5, 'lengthscale': 0.05, 'period': 0.2})\n",
    "exp.model.prior_mean = quadratic\n",
    "exp.maximum_likelihood_estimation()  # just for illustration; this does nothing since all parameters are fixed\n",
    "exp.model.fit(X0, y0)  # need to re-fit model, this is not automatic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a2aaf",
   "metadata": {},
   "source": [
    "# Showing how the API works - BayesOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3a913",
   "metadata": {},
   "source": [
    "Unfortunately, the \"dynamic plot\" functionality isn't working in this Notebook. Instead we just get the first snapshot of the optimsation routine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77915623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the objective function:\n",
    "def objective(x):\n",
    "    return jnp.ravel(x ** 2 * jnp.sin(5 * jnp.pi * x) ** 6.0)\n",
    "\n",
    "# plotting. Maximum occurs at roughly 0.9\n",
    "X = np.linspace(0., 1., num=100)\n",
    "y = objective(X)\n",
    "plt.plot(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. no user input, default RBF kernel with parameters inferred by mle, with subsequent Bayesian optimisation\n",
    "exp = Experiment(X0, y0, objective=objective)\n",
    "num_iters = 5\n",
    "# by default the acquisition function will be PI and the acquisition algorithm will be a Random search \n",
    "exp.run_bayes_opt(num_iters=3, dynamic_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. no user input, default RBF kernel but with a quadratic prior with parameters inferred by MLE, with subsequent\n",
    "# Bayesian optimisation using EI acquisition\n",
    "exp = Experiment(X0, y0, objective=objective, prior_mean=quadratic)\n",
    "num_iters = 5\n",
    "EI_acq = acq_func_builder('EI', margin=0.05)\n",
    "exp.run_bayes_opt(num_iters=3, acq_func=EI_acq, dynamic_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad475d",
   "metadata": {},
   "source": [
    "# Getting deeper into the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9639c438",
   "metadata": {},
   "source": [
    "Defining various basic kernels and combining them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b12e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla kernels - note than one doesn't have to specify the domain dimension at this point.\n",
    "rbf = RBF(sigma=0.2, lengthscale=0.1)\n",
    "per = Periodic(sigma=0.1, lengthscale=0.05, period=2.)\n",
    "mat = Matern(order='1/2', sigma=0.6, lengthscale=0.1)\n",
    "\n",
    "# constructing a kernel as an algebraic combination\n",
    "ker = 0.2*rbf + 2.4*mat*per\n",
    "\n",
    "print(ker)\n",
    "# evaluating on multi-dimensional inputs\n",
    "X1 = jnp.asarray([[0.1, 0.3, -0.5], [0., 4.1, -2.]]) # 2 points in R^3\n",
    "X2 = jnp.asarray([[0.1, 0.3, -0.5], [0., 4.1, -2.], [0.1, 2.1, -2.], [1., 0., -1.]]) # 4 points in R^3\n",
    "print(ker(X1, X2))  # outputs is 2x4 ---the number of points in X1 by the number of points in X2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da963759",
   "metadata": {},
   "source": [
    "Kernels with varying lengthscales in each coordinate dimension (not supported for periodic kernel as it's not clear what the generalisation should be):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbf kernel on R^3 with axis-dependent lengthscales\n",
    "rbf = RBF(sigma=0.2, lengthscale=[0.1, 0.2, 0.3])\n",
    "mat = Matern(order='1/2', sigma=0.6, lengthscale=[0.1, 0.4, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce0f9f",
   "metadata": {},
   "source": [
    "Model with a non-trivial prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7bdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianProcessReg(kernel_type='RBF', kernel_hyperparam_kwargs={'sigma': 0.5, 'lengthscale':0.1}, \n",
    "                          prior_mean=quadratic) # using the quadratic function defined earlier as the prior mean func\n",
    "# 'fit' to data \n",
    "model.fit(X0, y0)\n",
    "\n",
    "# making predictions\n",
    "X1 = jnp.asarray([[0.1], [0.], [-4.1]]) # 3 points in R\n",
    "means, covs = model.predict(X1)   \n",
    "\n",
    "print(means)\n",
    "print(covs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe441e34",
   "metadata": {},
   "source": [
    "Defining various acquisition functions and evaluating them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first define a model\n",
    "model = GaussianProcessReg(kernel_type='RBF', kernel_hyperparam_kwargs={'sigma': 0.5, 'lengthscale':0.1})\n",
    "# 'fit' to data \n",
    "model.fit(X0, y0)\n",
    "\n",
    "# vanilla acquisition functions\n",
    "PI_acq = acq_func_builder('PI', margin=0.01)\n",
    "EI_acq = acq_func_builder('EI', margin=0.01)\n",
    "UCB_acq = acq_func_builder('UCB', std_weight=0.01)\n",
    "\n",
    "\n",
    "# we can take linear combinations (pointwise addition of functions)\n",
    "acq_func = 0.1*PI_acq + 0.5*EI_acq + 0.02*UCB_acq\n",
    "\n",
    "# evaluating acquistion function - it takes as arguments the query point and the model\n",
    "print(acq_func(jnp.asarray([[0.2]]), model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a8e14d",
   "metadata": {},
   "source": [
    "Initialising optax solvers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adam(learning_rate=1e-2)\n",
    "acq_alg = OptaxAcqAlgBuilder(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081f1ad0",
   "metadata": {},
   "source": [
    "BayesOpt outside of the Experiment class ---experimenting with different kernels, hyperparameters, priors, acquisition functions and acquisition algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = jnp.asarray([[0.], [0.2], [0.6], [0.8]])\n",
    "y0 = objective(X0)\n",
    "\n",
    "# model with default RBF kernel\n",
    "model = GaussianProcessReg(kernel_hyperparam_kwargs={'sigma': 0.1, 'lengthscale':0.05}, \n",
    "                          prior_mean=quadratic, obs_noise_stdev=0.01) # using the quadratic function defined earlier as the prior mean func\n",
    "model.fit(X0, y0)\n",
    "\n",
    "# BayesOpt with (default) Random search as acquisition algorithm\n",
    "num_iters = 5\n",
    "acq_func = acq_func_builder('PI', margin=0.01)\n",
    "X, y, _ = opt_routine(acq_func, model, num_iters, objective, return_surrogates=False, dynamic_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with default RBF kernel\n",
    "model = GaussianProcessReg(kernel_type='Periodic', kernel_hyperparam_kwargs={'sigma': 0.1, 'lengthscale':0.05, 'period': 2}, \n",
    "                          prior_mean=quadratic, obs_noise_stdev=0.01) # using the quadratic function defined earlier as the prior mean func\n",
    "model.fit(X0, y0)\n",
    "\n",
    "# BayesOpt with (default) Random search as acquisition algorithm\n",
    "num_iters = 5\n",
    "acq_func = acq_func_builder('PI', margin=0.01) + 0.1*acq_func_builder('EI', margin=0.05)\n",
    "X, y, _ = opt_routine(acq_func, model, num_iters, objective, return_surrogates=False, dynamic_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4e6af",
   "metadata": {},
   "source": [
    "An example with a gradient-based acquisition algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with RBF kernel\n",
    "model = GaussianProcessReg(kernel_hyperparam_kwargs={'sigma': 0.1, 'lengthscale':0.05}, \n",
    "                          prior_mean=quadratic, obs_noise_stdev=0.01) # using the quadratic function defined earlier as the prior mean func\n",
    "model.fit(X0, y0)\n",
    "\n",
    "num_iters = 5\n",
    "acq_func = acq_func_builder('PI', margin=0.01)\n",
    "# building the optimizer that will be used for optimising the acqusition function\n",
    "optimizer = optax.adam(learning_rate=1e-2)\n",
    "acq_alg = OptaxAcqAlgBuilder(optimizer)\n",
    "X, y, _ = opt_routine(acq_func, model, num_iters, objective, acq_alg=acq_alg, dynamic_plot=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea74c9",
   "metadata": {},
   "source": [
    "An example with multi-dimensional input. This works in exactly the same way as the 1d examples, the domain dimension being inferred from the data. There's no 'dynamic plot' functionality yet however. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an objective with multi-dimensional data\n",
    "def objective_2(x, noise=0.05):\n",
    "        return jnp.ravel(\n",
    "            (1 - 5 * (x[:, 0] - 0.5) ** 2 - 5 * (x[:, 1] - 0.5) ** 2) * jnp.cos(3 * jnp.pi * (x[:, 0] - 0.5)) ** 6.0\n",
    "            * jnp.cos(3 * jnp.pi * (x[:, 1] - 0.5)) ** 4.0)\n",
    "    \n",
    "# plotting\n",
    "x_0 = np.sort(np.random.random(1000))\n",
    "x_1 = np.sort(np.random.random(1000))\n",
    "test_points = np.transpose([np.tile(x_0, 1000), np.repeat(x_1, 1000)])\n",
    "y = objective_2(test_points)\n",
    "#print(len(y))\n",
    "x_0, x_1 = np.meshgrid(x_0, x_1)\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.plot_surface(x_0, x_1, y.reshape(1000, 1000), alpha=1.0)#, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54beaf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some multi-diminsional data - x vals have to be in [0, 1]^N\n",
    "domain_dim = 2\n",
    "num_initial_samples = 10\n",
    "X0 = jnp.asarray(np.random.random((num_initial_samples, domain_dim)))\n",
    "y0 = objective_2(X0)\n",
    "\n",
    "# model with RBF kernel\n",
    "kernel_hyperparam_kwargs = {'sigma': 0.35, 'lengthscale': 0.11}\n",
    "model = GaussianProcessReg(kernel_hyperparam_kwargs=kernel_hyperparam_kwargs, domain_dim=2, obs_noise_stdev=0.001)\n",
    "model.fit(X0, y0)\n",
    "\n",
    "num_iters = 5\n",
    "acq_func = acq_func_builder('PI', margin=0.01)\n",
    "# building the optimizer that will be used for optimising the acquisition function\n",
    "optimizer = optax.adam(learning_rate=1e-2)\n",
    "acq_alg = OptaxAcqAlgBuilder(optimizer)\n",
    "X, y, _ = opt_routine(acq_func, model, num_iters, objective_2, acq_alg=acq_alg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c35fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
